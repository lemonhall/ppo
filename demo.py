import ale_py
ale_py.register_v5_envs()
import gymnasium as gym
from stable_baselines3 import DQN
from stable_baselines3.common.env_util import make_atari_env
from stable_baselines3.common.vec_env import VecFrameStack
from stable_baselines3.common.atari_wrappers import AtariWrapper
import numpy as np
import time
import os

model_path = "breakout_dqn_model.zip"

# æ£€æŸ¥æ˜¯å¦å·²ç»æœ‰è®­ç»ƒå¥½çš„æ¨¡å‹
if os.path.exists(model_path):
    print(f"å‘ç°å·²ä¿å­˜çš„æ¨¡å‹ï¼š{model_path}")
    choice = input("æ˜¯å¦ç›´æ¥åŠ è½½æ¨¡å‹å¼€å§‹æ¼”ç¤ºï¼Ÿ(y/n): ").lower()
    if choice == 'y' or choice == 'yes' or choice == '':
        print("æ­£åœ¨åŠ è½½å·²ä¿å­˜çš„æ¨¡å‹...")
        model = DQN.load(model_path)
        print("æ¨¡å‹åŠ è½½å®Œæˆï¼")
    else:
        print("å°†é‡æ–°è®­ç»ƒæ¨¡å‹...")
        # åˆ›å»ºè®­ç»ƒç¯å¢ƒ
        train_env = make_atari_env("BreakoutNoFrameskip-v4", n_envs=1, seed=0)
        train_env = VecFrameStack(train_env, n_stack=4)
        
        # åˆ›å»ºå¹¶è®­ç»ƒæ¨¡å‹
        model = DQN("CnnPolicy", train_env, verbose=1, buffer_size=10000)
        print("å¼€å§‹è®­ç»ƒæ¨¡å‹...")
        model.learn(total_timesteps=20000)
        print("è®­ç»ƒå®Œæˆï¼")
        
        # ä¿å­˜æ¨¡å‹
        model.save("breakout_dqn_model")
        print(f"æ¨¡å‹å·²ä¿å­˜ä¸º {model_path}")
else:
    print("æœªæ‰¾åˆ°å·²è®­ç»ƒçš„æ¨¡å‹ï¼Œå¼€å§‹è®­ç»ƒ...")
    # åˆ›å»ºè®­ç»ƒç¯å¢ƒ
    train_env = make_atari_env("BreakoutNoFrameskip-v4", n_envs=1, seed=0)
    train_env = VecFrameStack(train_env, n_stack=4)
    
    # åˆ›å»ºå¹¶è®­ç»ƒæ¨¡å‹
    model = DQN("CnnPolicy", train_env, verbose=1, buffer_size=10000)
    print("å¼€å§‹è®­ç»ƒæ¨¡å‹...")
    model.learn(total_timesteps=20000)
    print("è®­ç»ƒå®Œæˆï¼")
    
    # ä¿å­˜æ¨¡å‹
    model.save("breakout_dqn_model")
    print(f"æ¨¡å‹å·²ä¿å­˜ä¸º {model_path}")

# ç°åœ¨å¼€å§‹å¯è§†åŒ–æ¼”ç¤ºï¼
print("\n=== å¼€å§‹æ¸¸æˆæ¼”ç¤º ===\n")
print("æ³¨æ„ï¼šç”±äºæŠ€æœ¯é™åˆ¶ï¼Œå°†æ˜¾ç¤ºAIæ¸¸æˆè¿›åº¦è€Œä¸æ˜¯å®æ—¶ç”»é¢")
print("ä½†ä½ å¯ä»¥çœ‹åˆ°AIçš„å¾—åˆ†å’Œè¡¨ç°ç»Ÿè®¡")

# åˆ›å»ºå’Œè®­ç»ƒç¯å¢ƒç›¸åŒæ ¼å¼çš„æ¼”ç¤ºç¯å¢ƒ
visual_env = make_atari_env("BreakoutNoFrameskip-v4", n_envs=1, seed=42)
visual_env = VecFrameStack(visual_env, n_stack=4)

print("æ¸¸æˆç¯å¢ƒå·²åˆ›å»ºï¼")
print("æ¥ä¸‹æ¥ä½ å°†çœ‹åˆ°AIç©Breakoutçš„å®æ—¶ç»Ÿè®¡")
print("æŒ‰ Ctrl+C å¯ä»¥éšæ—¶åœæ­¢\n")

obs = visual_env.reset()
total_reward = 0
episode_count = 0
max_episodes = 5  # æ¼”ç¤º5å±€
step_count = 0

try:
    while episode_count < max_episodes:
        # è®©è®­ç»ƒå¥½çš„AIå†³å®šåŠ¨ä½œ
        action, _states = model.predict(obs, deterministic=True)
        
        # æ‰§è¡ŒåŠ¨ä½œ
        obs, rewards, dones, infos = visual_env.step(action)
        total_reward += rewards[0]
        step_count += 1
        
        # æ¯50æ­¥è¾“å‡ºä¸€æ¬¡è¿›åº¦
        if step_count % 50 == 0:
            print(f"æ­¥æ•°: {step_count:4d} | å½“å‰å¾—åˆ†: {total_reward:6.1f} | ç¬¬{episode_count + 1}å±€è¿›è¡Œä¸­...")
        
        if dones[0]:
            episode_count += 1
            print(f"\nğŸ¯ ç¬¬{episode_count}å±€æ¸¸æˆç»“æŸ - æœ€ç»ˆå¾—åˆ†: {total_reward:.1f} åˆ†")
            print(f"   æœ¬å±€ç”¨äº† {step_count} æ­¥")
            
            # é‡ç½®è®¡æ•°å™¨
            total_reward = 0
            step_count = 0
            
            if episode_count < max_episodes:
                print(f"\nå‡†å¤‡å¼€å§‹ç¬¬{episode_count + 1}å±€...")
                time.sleep(1)  # å±€é—´ä¼‘æ¯
                
except KeyboardInterrupt:
    print("\næ¼”ç¤ºè¢«ç”¨æˆ·åœæ­¢")

visual_env.close()
print(f"\nğŸ® æ¸¸æˆæ¼”ç¤ºç»“æŸï¼AIæ€»å…±ç©äº†{episode_count}å±€æ¸¸æˆ")
print("\nğŸ’¡ æç¤ºï¼šå¦‚æœæƒ³çœ‹åˆ°çœŸæ­£çš„æ¸¸æˆç”»é¢ï¼Œéœ€è¦å®‰è£…é¢å¤–çš„å¯è§†åŒ–åº“")